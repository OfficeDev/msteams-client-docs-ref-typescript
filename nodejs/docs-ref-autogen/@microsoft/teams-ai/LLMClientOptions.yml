### YamlMime:TSType
name: LLMClientOptions
uid: '@microsoft/teams-ai.LLMClientOptions'
package: '@microsoft/teams-ai'
summary: Options for an LLMClient instance.
fullName: LLMClientOptions<TContent>
remarks: ''
isDeprecated: false
type: interface
properties:
  - name: history_variable
    uid: '@microsoft/teams-ai.LLMClientOptions.history_variable'
    package: '@microsoft/teams-ai'
    summary: Optional. Memory variable used for storing conversation history.
    fullName: history_variable
    remarks: >-
      The history will be stored as a `Message[]` and the variable defaults to
      `conversation.history`.
    isDeprecated: false
    syntax:
      content: 'history_variable?: string'
      return:
        description: ''
        type: string
  - name: input_variable
    uid: '@microsoft/teams-ai.LLMClientOptions.input_variable'
    package: '@microsoft/teams-ai'
    summary: Optional. Memory variable used for storing the users input message.
    fullName: input_variable
    remarks: >-
      The users input is expected to be a `string` but it's optional and
      defaults to `temp.input`.
    isDeprecated: false
    syntax:
      content: 'input_variable?: string'
      return:
        description: ''
        type: string
  - name: logRepairs
    uid: '@microsoft/teams-ai.LLMClientOptions.logRepairs'
    package: '@microsoft/teams-ai'
    summary: Optional. If true, any repair attempts will be logged to the console.
    fullName: logRepairs
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'logRepairs?: boolean'
      return:
        description: ''
        type: boolean
  - name: max_history_messages
    uid: '@microsoft/teams-ai.LLMClientOptions.max_history_messages'
    package: '@microsoft/teams-ai'
    summary: Optional. Maximum number of conversation history messages to maintain.
    fullName: max_history_messages
    remarks: >-
      The number of tokens worth of history included in the prompt is controlled
      by the

      `ConversationHistory` section of the prompt. This controls the automatic
      pruning of the

      conversation history that's done by the LLMClient instance. This helps
      keep your memory from

      getting too big and defaults to a value of `10` (or 5 turns.)
    isDeprecated: false
    syntax:
      content: 'max_history_messages?: number'
      return:
        description: ''
        type: number
  - name: max_repair_attempts
    uid: '@microsoft/teams-ai.LLMClientOptions.max_repair_attempts'
    package: '@microsoft/teams-ai'
    summary: >-
      Optional. Maximum number of automatic repair attempts the LLMClient
      instance will make.
    fullName: max_repair_attempts
    remarks: >-
      This defaults to a value of `3` and can be set to `0` if you wish to
      disable repairing of bad responses.
    isDeprecated: false
    syntax:
      content: 'max_repair_attempts?: number'
      return:
        description: ''
        type: number
  - name: model
    uid: '@microsoft/teams-ai.LLMClientOptions.model'
    package: '@microsoft/teams-ai'
    summary: AI model to use for completing prompts.
    fullName: model
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'model: PromptCompletionModel'
      return:
        description: ''
        type: <xref uid="@microsoft/teams-ai.PromptCompletionModel" />
  - name: template
    uid: '@microsoft/teams-ai.LLMClientOptions.template'
    package: '@microsoft/teams-ai'
    summary: Prompt to use for the conversation.
    fullName: template
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'template: PromptTemplate'
      return:
        description: ''
        type: <xref uid="@microsoft/teams-ai.PromptTemplate" />
  - name: tokenizer
    uid: '@microsoft/teams-ai.LLMClientOptions.tokenizer'
    package: '@microsoft/teams-ai'
    summary: Optional. Tokenizer to use when rendering the prompt or counting tokens.
    fullName: tokenizer
    remarks: If not specified a new instance of `GPT3Tokenizer` will be created.
    isDeprecated: false
    syntax:
      content: 'tokenizer?: Tokenizer'
      return:
        description: ''
        type: <xref uid="@microsoft/teams-ai.Tokenizer" />
  - name: validator
    uid: '@microsoft/teams-ai.LLMClientOptions.validator'
    package: '@microsoft/teams-ai'
    summary: Optional. Response validator to use when completing prompts.
    fullName: validator
    remarks: >-
      If not specified a new instance of `DefaultResponseValidator` will be
      created. The

      DefaultResponseValidator returns a `Validation` that says all responses
      are valid.
    isDeprecated: false
    syntax:
      content: 'validator?: PromptResponseValidator<TContent>'
      return:
        description: ''
        type: >-
          <xref uid="@microsoft/teams-ai.PromptResponseValidator"
          />&lt;TContent&gt;
