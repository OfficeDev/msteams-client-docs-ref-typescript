### YamlMime:TSType
name: LLMClient
uid: '@microsoft/teams-ai.LLMClient'
package: '@microsoft/teams-ai'
summary: >-
  Represents an LLM (Language Learning Model) client.

  This class provides methods for configuring and interacting with the LLM
  model.
fullName: LLMClient<TContent>
remarks: ''
isDeprecated: false
type: class
constructors:
  - name: LLMClient<TContent>(LLMClientOptions<TContent>)
    uid: '@microsoft/teams-ai.LLMClient.constructor'
    package: '@microsoft/teams-ai'
    summary: Creates a new `LLMClient` instance.
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'new LLMClient(options: LLMClientOptions<TContent>)'
      parameters:
        - id: options
          type: <xref uid="@microsoft/teams-ai.LLMClientOptions" />&lt;TContent&gt;
          description: Options to configure the instance with.
properties:
  - name: options
    uid: '@microsoft/teams-ai.LLMClient.options'
    package: '@microsoft/teams-ai'
    summary: Configured options for this LLMClient instance.
    fullName: options
    remarks: ''
    isDeprecated: false
    syntax:
      content: 'options: ConfiguredLLMClientOptions<TContent>'
      return:
        description: ''
        type: >-
          <xref uid="@microsoft/teams-ai.ConfiguredLLMClientOptions"
          />&lt;TContent&gt;
methods:
  - name: addFunctionResultToHistory(Memory, string, any)
    uid: '@microsoft/teams-ai.LLMClient.addFunctionResultToHistory'
    package: '@microsoft/teams-ai'
    summary: Adds a result from a `function_call` to the history.
    remarks: ''
    isDeprecated: false
    syntax:
      content: >-
        function addFunctionResultToHistory(memory: Memory, name: string,
        results: any)
      parameters:
        - id: memory
          type: <xref uid="@microsoft/teams-ai.Memory" />
          description: An interface for accessing state values.
        - id: name
          type: string
          description: Name of the function that was called.
        - id: results
          type: any
          description: Results returned by the function.
  - name: completePrompt(TurnContext, Memory, PromptFunctions)
    uid: '@microsoft/teams-ai.LLMClient.completePrompt'
    package: '@microsoft/teams-ai'
    summary: Completes a prompt.
    remarks: >-
      The `input` parameter is optional but if passed in, will be assigned to
      memory using the

      configured `input_variable`. If it's not passed in an attempt will be made
      to read it

      from memory so passing it in or assigning to memory works. In either case,
      the `input`

      variable is only used when constructing a user message that, will be added
      to the

      conversation history and formatted like `{ role: 'user', content: input
      }`.


      It's important to note that if you want the users input sent to the model
      as part of the

      prompt, you will need to add a `UserMessage` section to your prompt. The
      wave does not do

      anything to modify your prompt, except when performing repairs and those
      changes are

      temporary.


      When the model successfully returns a valid (or repaired) response, a
      'user' message (if

      input was detected) and 'assistant' message will be automatically added to
      the conversation

      history. You can disable that behavior by setting `max_history_messages`
      to `0`.


      The response returned by `completePrompt()` will be strongly typed by the
      validator you're

      using. The `DefaultResponseValidator` returns a `string` and the
      `JSONResponseValidator`

      will return either an `object` or if a JSON Schema is provided, an
      instance of `TContent`.

      When using a custom validator, the validator is return any type of content
      it likes.


      A successful response is indicated by `response.status == 'success'` and
      the content can be

      accessed via `response.message.content`.  If a response is invalid it will
      have a

      `response.status == 'invalid_response'` and the `response.message` will be
      a string containing

      the validator feedback message.  There are other status codes for various
      errors and in all

      cases except `success` the `response.message` will be of type `string`.
    isDeprecated: false
    syntax:
      content: >-
        function completePrompt(context: TurnContext, memory: Memory, functions:
        PromptFunctions): Promise<PromptResponse<TContent>>
      parameters:
        - id: context
          type: TurnContext
          description: Current turn context.
        - id: memory
          type: <xref uid="@microsoft/teams-ai.Memory" />
          description: An interface for accessing state values.
        - id: functions
          type: <xref uid="@microsoft/teams-ai.PromptFunctions" />
          description: Functions to use when rendering the prompt.
      return:
        description: A `PromptResponse` with the status and message.
        type: >-
          Promise&lt;<xref uid="@microsoft/teams-ai.PromptResponse"
          />&lt;TContent&gt;&gt;
